---
layout: page
title: Projects
permalink: /projects/
---

### Offline Video Facial Recognition/Object Detection

_(2017)_

> In addition to its camera feed application counterpart, this application opened doors to more intensive offline parallel processing with supercomputing clusters, leveraging heavier neural networks, and ensured precise frame-by-frame operations. Tens of objects could be detected for each frame so that search could be exhaustive.

![img](/public/imgs/video.jpg){: style="width: 95%;max-width:600px" }

-----------------

### Camera Feed Facial Recognition/Object Detection

_(2017)_

> Built an application to display camera feed and perform facial recognition and object detection in Python with core C++ function calls ([dlib](http://dlib.net/) and TensorFlow). Extensive effort was put to multithreading/processing and load balancing so that program could run fast even on a Raspberry Pi. User could toggle different states, e.g. display, training, recognizing. Could record logged-in user list and do all sorts of things. This was a project that blended AI (image/face transformation) and machine learning models (for identity classification) with good engineering and programming.

![img](/public/imgs/camera0.jpg){: style="width: 95%;max-width:600px" }
![img](/public/imgs/camera1.jpg){: style="width: 95%;max-width:600px" }

-----------------

### [Ten Million Celebrity Faces Search](/projects/facesearch)

_(2017)_

> Built a state-of-the-art Web application with MongoDB and Flask to detect, transform and index features of ten million faces. It supported very fast searches with user uploaded photos. The application leveraged the latest computer vision neural networks ([dlib](http://dlib.net/)) and nearest neighbors and clustering algorithms ([Faiss](https://github.com/facebookresearch/faiss)).

![img](/public/imgs/celebsearch0.jpg){: style="width: 95%;max-width:600px" }

-----------------

### [Kaggle Competition: Rental Listing Inquiries](https://github.com/terencezl/kaggle-rental-listing-inquiries)

_(2017)_

> Built machine learning classification models (SVMs, random forests, boosted trees) with scikit-learn to predict viewer interest levels of 80k rental listings. Performed text feature engineering and model comparison.

![img](/public/imgs/kaggle.jpg){: style="width: 95%;max-width:500px" }

-----------------

## [R-practice](https://github.com/terencezl/R-practice)

_(2017)_

> Assorted practice projects and assignments written in R.

-----------------

### [Case Study of Myopia with Logistic Regression](/projects/myopia.html)

_(2016)_

> Selected the optimal generalized linear model and identified influencing factors such as inheritance, gender, indoors & outdoors time spent and eyeball anatomy.

![img](/public/imgs/myopia.jpg){: style="width: 95%;max-width:600px" }

-----------------

### Ceramics Database

_(2016)_

> Led a two-person team. Wrote the great majority of the code. The database was built with Django and MySQL, equipped with modern mobile Web technologies. Customized tabulation/graphing, user registration and contribution were supported. Project helped get $100,000 research grant.

![img](/public/imgs/ceramics.jpg){: style="width: 95%;max-width:600px" }

-----------------

### Homework Collector

_(2016)_

> Website allows students to submit their homework with verification and file format control. Email submission of attachments and confirmation are also allowed. Has convenient record keeping and output.

![img](/public/imgs/collecthw.jpg){: style="width: 50%;max-width:300px" }

-----------------

## [pyvasp-workflow](https://github.com/terencezl/pyvasp-workflow)

_(2014 - 2016)_

> A simple yet flexible programmatic workflow of describing, submitting and analyzing VASP jobs.

-----------------

## [pydass_vasp](https://github.com/terencezl/pydass_vasp)

_(2014 - 2016)_

> Convenient Python modules and wrapping executable scripts.

-----------------

## [ScriptsForVASP](https://github.com/terencezl/ScriptsForVASP)

_(2014)_

> Making life easier using scripting languages (Bash and Python) to facilitate multiple VASP simulation jobs preparation, submission and analysis.
